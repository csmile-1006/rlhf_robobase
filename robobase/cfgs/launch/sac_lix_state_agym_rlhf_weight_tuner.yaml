# @package _global_

defaults:
  - ../env: null  # Please specify environment to use in command line
  - ../method: sac_lix
  - ../reward_method: weight_tuner

env:
  reward_mode: initial

pixels: false
frame_stack: 1
action_repeat: 1
num_train_envs: 4
num_eval_episodes: 10
log_every: 200
eval_every_steps: 10000
save_snapshot: true
snapshot_every_n: 50000
num_train_frames: 1001000

rlhf:
  use_rlhf: true
  feedback_type: gemini
  comparison_type: sequential_pairwise
  query_type: timestep
  max_feedback: 1000
  update_every_steps: 25000
  num_pretrain_steps: 50000
  num_train_frames: 1000
  snapshot_every_n: ${rlhf.update_every_steps}
  gemini:
    model_type: gemini-1.5-pro
    target_viewpoints: ${env.query_keys}

rlhf_replay:
  num_queries: 100
  num_labels: 1
  seq_len: 200
  feedback_batch_size: 256
  max_episode_number: 0

hydra:
  run:
    dir: ./exp_local/state_sac_lix_rlhf/agym_${env.task_name}_rlhf_weight_tuner_${rlhf.feedback_type}_numf${rlhf.max_feedback}_numq${rlhf_replay.num_queries}_update${rlhf.update_every_steps}_pretrain${rlhf.num_pretrain_steps}_${now:%Y%m%d%H%M%S}
